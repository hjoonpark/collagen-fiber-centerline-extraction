2022-11-13 03:29:01 INFO PyTorch implementation of "Variational auto-encoder for collagen fiber centerline generation and extraction in fibrotic cancer tissues"
2022-11-13 03:29:01 INFO =============== Training Stage 1 ===============
Loaded [2/36223]
Loaded [1002/36223]
Loaded [2002/36223]
Loaded [3002/36223]
Loaded [4002/36223]
Loaded [5002/36223]
Loaded [6002/36223]
Loaded [7002/36223]
Loaded [8002/36223]
Loaded [9002/36223]
Loaded [10002/36223]
Loaded [11002/36223]
Loaded [12002/36223]
Loaded [13002/36223]
Loaded [14002/36223]
Loaded [15002/36223]
Loaded [16002/36223]
Loaded [17002/36223]
Loaded [18002/36223]
Loaded [19002/36223]
Loaded [20002/36223]
Loaded [21002/36223]
Loaded [22002/36223]
Loaded [23002/36223]
Loaded [24002/36223]
Loaded [25002/36223]
Loaded [26002/36223]
Loaded [27002/36223]
Loaded [28002/36223]
Loaded [29002/36223]
Loaded [30002/36223]
Loaded [31002/36223]
Loaded [32002/36223]
Loaded [33002/36223]
Loaded [34002/36223]
Loaded [35002/36223]
Loaded [36002/36223]
2022-11-13 03:29:20 INFO Loaded centerlines=torch.Size([36223, 1, 256, 256]), torch.float32 min/max=(0.00, 1.00), mean/std=(0.02, 0.15)
2022-11-13 03:29:20 INFO Loaded properties=torch.Size([36223, 6]), torch.float32 min/max=(-4.72, 8.31), mean/std=(0.00, 1.00)
2022-11-13 03:29:20 INFO CUDA is available
2022-11-13 03:29:21 INFO DuoVAE(
  (encoder_x): EncoderX(
    (encoder): Sequential(
      (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.2, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): LeakyReLU(negative_slope=0.2, inplace=True)
      (9): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): LeakyReLU(negative_slope=0.2, inplace=True)
      (12): View()
      (13): Linear(in_features=8192, out_features=128, bias=True)
      (14): LeakyReLU(negative_slope=0.2, inplace=True)
      (15): Linear(in_features=128, out_features=128, bias=True)
      (16): LeakyReLU(negative_slope=0.2, inplace=True)
      (17): Linear(in_features=128, out_features=24, bias=True)
    )
  )
  (decoder_x): DecoderX(
    (decoder): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): LeakyReLU(negative_slope=0.2, inplace=True)
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): LeakyReLU(negative_slope=0.2, inplace=True)
      (4): Linear(in_features=128, out_features=8192, bias=True)
      (5): LeakyReLU(negative_slope=0.2, inplace=True)
      (6): View()
      (7): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (9): LeakyReLU(negative_slope=0.2, inplace=True)
      (10): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (12): LeakyReLU(negative_slope=0.2, inplace=True)
      (13): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (14): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (15): LeakyReLU(negative_slope=0.2, inplace=True)
      (16): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (18): LeakyReLU(negative_slope=0.2, inplace=True)
      (19): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (encoder_y): EncoderY(
    (encoder): Sequential(
      (0): Linear(in_features=6, out_features=12, bias=True)
      (1): LeakyReLU(negative_slope=0.2, inplace=True)
      (2): Linear(in_features=12, out_features=12, bias=True)
      (3): LeakyReLU(negative_slope=0.2, inplace=True)
      (4): Linear(in_features=12, out_features=12, bias=True)
    )
  )
  (decoder_y): DecoderY(
    (decoder): Sequential(
      (0): Linear(in_features=6, out_features=12, bias=True)
      (1): LeakyReLU(negative_slope=0.2, inplace=True)
      (2): Linear(in_features=12, out_features=12, bias=True)
      (3): LeakyReLU(negative_slope=0.2, inplace=True)
      (4): Linear(in_features=12, out_features=6, bias=True)
    )
  )
)
2022-11-13 03:29:21 INFO parameters={
    "data_dir": "data/36k",
    "train": {
        "n_epoch": 10000000,
        "batch_size": 800,
        "lr": 0.0002,
        "log_freq": 2,
        "save_freq": 50
    },
    "duovae": {
        "z_dim": 6,
        "w_dim": 6,
        "x_recon_weight": 2.0,
        "y_recon_weight": 1.0,
        "beta_z": 0.005,
        "beta_w": 0.005,
        "beta_w2": 0.005,
        "hid_channel": 32,
        "hid_dim_x": 128,
        "hid_dim_y": 12
    }
}
2022-11-13 03:29:21 INFO Trainable parameters=2,260,227
2022-11-13 03:29:21 INFO Device=cuda:0, GPU Ids=[0]
2022-11-13 03:29:21 INFO Training on 36,223 number of data
2022-11-13 03:29:56 INFO   [0] NVIDIA RTX A6000, Memory: total(49.1 GB) used(45.3 GB) free(3.4 GB) 92% | temperature(71 'C)
2022-11-13 03:30:29 INFO epoch:2/10000000 x_recon:24.6093 y_recon:42.4506 y_recon2:285.0869 kl_div_z:0.2876 kl_div_w:1.6710 kl_div_w2:0.0408 
2022-11-13 03:31:36 INFO epoch:4/10000000 x_recon:13.6672 y_recon:38.4877 y_recon2:276.3016 kl_div_z:0.0245 kl_div_w:1.6546 kl_div_w2:0.0474 
2022-11-13 03:32:43 INFO epoch:6/10000000 x_recon:11.3600 y_recon:30.9363 y_recon2:255.1907 kl_div_z:0.0142 kl_div_w:1.4553 kl_div_w2:0.0918 
2022-11-13 03:33:50 INFO epoch:8/10000000 x_recon:10.3963 y_recon:25.7836 y_recon2:202.7319 kl_div_z:0.0155 kl_div_w:1.2642 kl_div_w2:0.3125 
2022-11-13 03:34:57 INFO epoch:10/10000000 x_recon:9.9626 y_recon:23.6681 y_recon2:169.3109 kl_div_z:0.0138 kl_div_w:1.2988 kl_div_w2:0.6572 
2022-11-13 03:34:57 INFO   [0] NVIDIA RTX A6000, Memory: total(49.1 GB) used(45.3 GB) free(3.4 GB) 92% | temperature(76 'C)
2022-11-13 03:34:58 INFO   train losses saved: output/stage1/log/losses.json, output/stage1/log/losses.png
2022-11-13 03:34:58 INFO   model saved: output/stage1/model
2022-11-13 03:34:58 INFO   y-traverse saved: output/stage1/visualization/y_trav_00010.png
2022-11-13 03:36:05 INFO epoch:12/10000000 x_recon:9.7610 y_recon:22.3163 y_recon2:150.4930 kl_div_z:0.0121 kl_div_w:1.1914 kl_div_w2:0.9481 
2022-11-13 03:37:12 INFO epoch:14/10000000 x_recon:9.6740 y_recon:21.4464 y_recon2:137.5137 kl_div_z:0.0110 kl_div_w:1.1180 kl_div_w2:1.2237 
2022-11-13 03:38:19 INFO epoch:16/10000000 x_recon:9.6402 y_recon:20.8012 y_recon2:127.9122 kl_div_z:0.0107 kl_div_w:1.1326 kl_div_w2:1.4754 
2022-11-13 03:39:26 INFO epoch:18/10000000 x_recon:9.6232 y_recon:19.8709 y_recon2:121.0060 kl_div_z:0.0110 kl_div_w:1.2050 kl_div_w2:1.7077 
2022-11-13 03:40:33 INFO epoch:20/10000000 x_recon:9.5951 y_recon:19.1480 y_recon2:113.2498 kl_div_z:0.0111 kl_div_w:1.5333 kl_div_w2:1.9307 
2022-11-13 03:40:33 INFO   [0] NVIDIA RTX A6000, Memory: total(49.1 GB) used(45.3 GB) free(3.4 GB) 92% | temperature(75 'C)
2022-11-13 03:40:34 INFO   train losses saved: output/stage1/log/losses.json, output/stage1/log/losses.png
2022-11-13 03:40:34 INFO   model saved: output/stage1/model
2022-11-13 03:40:34 INFO   y-traverse saved: output/stage1/visualization/y_trav_00020.png
2022-11-13 03:41:41 INFO epoch:22/10000000 x_recon:9.5802 y_recon:17.4466 y_recon2:105.9449 kl_div_z:0.0115 kl_div_w:1.7651 kl_div_w2:2.1722 
2022-11-13 03:42:48 INFO epoch:24/10000000 x_recon:9.5773 y_recon:16.2114 y_recon2:98.1662 kl_div_z:0.0109 kl_div_w:2.0614 kl_div_w2:2.4328 
2022-11-13 03:43:55 INFO epoch:26/10000000 x_recon:9.5747 y_recon:15.1963 y_recon2:89.4765 kl_div_z:0.0105 kl_div_w:2.4768 kl_div_w2:2.7080 
